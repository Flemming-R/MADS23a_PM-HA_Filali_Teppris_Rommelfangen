{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAREFUL, ONE RUN CAN COST QUITE FAST A LOT, MAYBE CHANGE TO gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# you need to create a .env file in the root of the project with following key:\n",
    "# OPENAI_API_KEY=\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "tools = [PythonREPLTool(verbose=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "\n",
      "You are a helpful assistant. You are executing a plan to answer a process mining task question.\n",
      "For this you have two dataset available that the python tool can load:\n",
      "- Data/DomesticDeclarations.xes\n",
      "- Data/InternationalDeclarations.xes\n",
      "You can get started with:\n",
      "\n",
      "```python\n",
      "import pm4py\n",
      "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
      "\n",
      "# Load the event logs\n",
      "domestic_log = xes_importer.apply('Data/DomesticDeclarations.xes')\n",
      "international_log = xes_importer.apply('Data/InternationalDeclarations.xes')\n",
      "\n",
      "# Print the summary of the logs to understand the structure\n",
      "domestic_summary = pm4py.get_event_attributes(domestic_log)\n",
      "international_summary = pm4py.get_event_attributes(international_log)\n",
      "```\n",
      "\n",
      "\n",
      "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{messages}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant. You are executing a plan to answer a process mining task question.\n",
    "For this you have two dataset available that the python tool can load:\n",
    "- Data/DomesticDeclarations.xes\n",
    "- Data/InternationalDeclarations.xes\n",
    "You can get started with:\n",
    "\n",
    "```python\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "\n",
    "# Load the event logs\n",
    "domestic_log = xes_importer.apply('Data/DomesticDeclarations.xes')\n",
    "international_log = xes_importer.apply('Data/InternationalDeclarations.xes')\n",
    "\n",
    "# Print the summary of the logs to understand the structure\n",
    "domestic_summary = pm4py.get_event_attributes(domestic_log)\n",
    "international_summary = pm4py.get_event_attributes(international_log)\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(SYSTEM_PROMPT),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "prompt.pretty_print()\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=model_name)\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Markdown, display\n",
    "# test_runnable = agent_executor\n",
    "# md_answer =test_runnable.invoke({\"messages\": [(\"user\", \"What attributes do the logs have?\")]})[\"messages\"][-1].content\n",
    "\n",
    "# display(Markdown(md_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow to solve the process mining task using python.\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the process mining task, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "The Executer Agent will have a PythonREPL tool to execute your plan and data will be available.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=model_name, temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=model_name, temperature=0\n",
    ").with_structured_output(Act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"messages\": [(\"user\", task_formatted)]}\n",
    "    )\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    output = await replanner.ainvoke(state)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        return {\"plan\": output.action.steps}\n",
    "\n",
    "\n",
    "def should_end(state: PlanExecute) -> Literal[\"agent\", \"__end__\"]:\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"__end__\"\n",
    "    else:\n",
    "        return \"agent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Add the plan node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Add the execution step\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Add a replan node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# From plan we go to agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# From agent, we replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    ")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keno/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To define the key objectives of the process being analyzed, we need to understand the context and purpose of the processes captured in the event logs. Let's start by examining the summaries of the DomesticDeclarations.xes and InternationalDeclarations.xes logs to get insights into the activities, cases, and event attributes. This will help us understand the processes better and define their key objectives.\n",
       "\n",
       "I'll proceed to load the logs and print their summaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b585e52a90fa4ce6add812ec0ed5b38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c179aaecf2b44468897d09d020ab8c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e58bd5f00cd4a78b7a0b82fd7bb174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54903563c0fe40938268a2ec1fa462b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mcontent='' name='Python_REPL' tool_call_id='call_ZdZu0YP5nCvSeVzJMqTwFqPb'\u001b[0m['concept:name', 'org:resource', 'id', 'time:timestamp', 'org:role']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The summaries of the logs indicate that both event logs contain the following attributes:\n",
       "\n",
       "- `concept:name`: The name of the event (activity).\n",
       "- `org:resource`: The resource (person or system) involved in the event.\n",
       "- `id`: The unique identifier for each event.\n",
       "- `time:timestamp`: The timestamp when the event occurred.\n",
       "- `org:role`: The role of the resource involved.\n",
       "\n",
       "Based on these attributes, we can infer that the processes involve various activities performed by different resources at specific times, with each event having a unique identifier and associated role.\n",
       "\n",
       "### Key Objectives\n",
       "To define the key objectives of the processes being analyzed, we can consider the following:\n",
       "\n",
       "1. **Efficiency**: Ensure that the process is completed in a timely manner with minimal delays.\n",
       "2. **Effectiveness**: Ensure that the process achieves its intended outcomes and goals.\n",
       "3. **Compliance**: Ensure that the process adheres to relevant regulations, standards, and policies.\n",
       "4. **Resource Utilization**: Optimize the allocation and utilization of resources (both human and system) involved in the process.\n",
       "5. **Quality**: Ensure that the process outputs meet the required quality standards and customer expectations.\n",
       "6. **Transparency**: Provide visibility into the process for stakeholders to monitor and understand the progress and performance.\n",
       "\n",
       "These objectives can guide the analysis and improvement of the processes captured in the Domestic and International Declarations event logs. \n",
       "\n",
       "Would you like to proceed to the next step, or focus on any specific objective in more detail?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4940e992b9a4052b70cb1d9af04c732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa76976dda04fc8b08176476ca73292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11673c881d64881a566569b35b2bf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dfb2130e3b495b8da72247bbdbdcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Both the Domestic and International event logs have the following attributes:\n",
       "\n",
       "- `concept:name`: Name of the event or activity.\n",
       "- `org:resource`: The resource (e.g., person or system) performing the event.\n",
       "- `id`: Unique identifier for the event.\n",
       "- `time:timestamp`: Timestamp of when the event occurred.\n",
       "- `org:role`: The role of the resource performing the event.\n",
       "\n",
       "Next, we will identify the critical activities and milestones within these processes. This can be done by extracting the most frequent and significant activities from the logs. Let's proceed with analyzing the most frequent activities in both logs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It seems there was an error because the module `pm4py.statistics.traces.log` couldn't be found. The correct module to use for extracting the frequency of activities is `pm4py.statistics.end_activities.log` for end activities or `pm4py.statistics.start_activities.log` for start activities.\n",
       "\n",
       "Let's correct the approach and extract the most frequent activities from both logs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are the most frequent start and end activities for both the Domestic and International logs:\n",
       "\n",
       "### Domestic Log\n",
       "- **Top Start Activities:**\n",
       "  - `Declaration SUBMITTED by EMPLOYEE`: 10,365 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 135 occurrences\n",
       "\n",
       "- **Top End Activities:**\n",
       "  - `Payment Handled`: 10,043 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 134 occurrences\n",
       "  - `Declaration REJECTED by EMPLOYEE`: 284 occurrences\n",
       "  - `Declaration REJECTED by MISSING`: 30 occurrences\n",
       "  - `Declaration REJECTED by ADMINISTRATION`: 5 occurrences\n",
       "  - `Declaration REJECTED by SUPERVISOR`: 4 occurrences\n",
       "\n",
       "### International Log\n",
       "- **Top Start Activities:**\n",
       "  - `Start trip`: 740 occurrences\n",
       "  - `Declaration SUBMITTED by EMPLOYEE`: 407 occurrences\n",
       "  - `Permit SUBMITTED by EMPLOYEE`: 5,294 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 8 occurrences\n",
       "\n",
       "- **Top End Activities:**\n",
       "  - `Payment Handled`: 5,646 occurrences\n",
       "  - `End trip`: 593 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 54 occurrences\n",
       "  - `Permit REJECTED by MISSING`: 8 occurrences\n",
       "  - `Declaration REJECTED by MISSING`: 11 occurrences\n",
       "  - `Declaration REJECTED by EMPLOYEE`: 130 occurrences\n",
       "  - `Declaration FINAL_APPROVED by SUPERVISOR`: 1 occurrence\n",
       "  - `Send Reminder`: 2 occurrences\n",
       "  - `Request Payment`: 3 occurrences\n",
       "  - `Declaration REJECTED by SUPERVISOR`: 1 occurrence\n",
       "\n",
       "These activities represent critical steps and milestones within the processes. The next steps would be to determine the desired outcomes and performance standards for each activity and select appropriate KPIs to measure their efficiency, effectiveness, and quality."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To determine the desired outcomes and performance standards for each activity in the event logs, we need to understand the structure of the logs and the typical activities that occur in each process. This information will help us define specific outcomes and standards for each activity.\n",
       "\n",
       "Let's start by loading the event logs and summarizing their structures to identify the activities and attributes present in each log. \n",
       "\n",
       "I'll execute the initial code to load the logs and print the summaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To select Key Performance Indicators (KPIs) that measure the efficiency, effectiveness, and quality of the process, we need to first understand the structure and the key attributes of the event logs available. This will help us identify the relevant data points that can be used to measure these aspects.\n",
       "\n",
       "Let's start by loading the event logs and printing the summary of the logs to understand their structure and attributes.\n",
       "\n",
       "I'll execute the following steps:\n",
       "1. Load the event logs for both `DomesticDeclarations` and `InternationalDeclarations`.\n",
       "2. Print the summary of the logs to identify key attributes.\n",
       "\n",
       "I will start by loading the event logs and printing their summaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcc43890f3e47efa6a202c3f7456971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e08152e7621404798afd67ccd16dd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The summary of the logs indicates the following key attributes are available for both domestic and international declarations:\n",
       "\n",
       "- `concept:name`: The name of the event.\n",
       "- `org:resource`: The resource (person or system) responsible for the event.\n",
       "- `id`: The unique identifier for the event.\n",
       "- `time:timestamp`: The timestamp of when the event occurred.\n",
       "- `org:role`: The role associated with the event.\n",
       "\n",
       "Based on these attributes, we can select KPIs that measure the efficiency, effectiveness, and quality of the process:\n",
       "\n",
       "### Efficiency KPIs:\n",
       "1. **Cycle Time**: The total time taken to complete a process from start to finish (`time:timestamp`).\n",
       "2. **Resource Utilization**: The workload distribution among different resources (`org:resource`).\n",
       "\n",
       "### Effectiveness KPIs:\n",
       "1. **Throughput**: The number of processes completed within a specific time frame (`id` and `time:timestamp`).\n",
       "2. **Process Compliance**: The adherence to predefined process steps (`concept:name`).\n",
       "\n",
       "### Quality KPIs:\n",
       "1. **Error Rate**: The number of deviations or exceptions from the standard process (`concept:name` indicating exceptions or reworks).\n",
       "2. **Satisfaction Rate**: Feedback from stakeholders (though not directly available in the logs, can be correlated with `org:role` and `concept:name`).\n",
       "\n",
       "These KPIs are specific to the available data attributes and can be measured, achieved, and are relevant to the process. They can also be time-bound by analyzing the `time:timestamp` attribute.\n",
       "\n",
       "Next, we can proceed to validate these KPIs with stakeholders to ensure they align with business goals and then move on to implement and collect data for analysis.\n",
       "\n",
       "Would you like to proceed with any additional analysis or validation steps for these KPIs?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To ensure that the KPIs for the process mining task are specific, measurable, achievable, relevant, and time-bound (SMART), we need to define the KPIs in the context of the available datasets. Here are some potential KPIs we could consider:\n",
       "\n",
       "1. **Cycle Time**:\n",
       "   - **Specific**: The total time taken to complete a declaration from start to finish.\n",
       "   - **Measurable**: Average cycle time in days/hours.\n",
       "   - **Achievable**: Based on historical data, set a target cycle time.\n",
       "   - **Relevant**: Directly impacts customer satisfaction and operational efficiency.\n",
       "   - **Time-bound**: Measured monthly or quarterly.\n",
       "\n",
       "2. **Conformance Rate**:\n",
       "   - **Specific**: The percentage of declarations that follow the standard process model.\n",
       "   - **Measurable**: Number of conformant cases divided by the total number of cases.\n",
       "   - **Achievable**: Set a target based on industry standards or historical data.\n",
       "   - **Relevant**: Ensures adherence to the defined process, reducing errors and exceptions.\n",
       "   - **Time-bound**: Measured monthly or quarterly.\n",
       "\n",
       "3. **Throughput Rate**:\n",
       "   - **Specific**: The number of declarations processed within a specific time period.\n",
       "   - **Measurable**: Number of declarations per week/month.\n",
       "   - **Achievable**: Based on resource capacity and historical data.\n",
       "   - **Relevant**: Indicates the efficiency of the process in handling workload.\n",
       "   - **Time-bound**: Measured weekly or monthly.\n",
       "\n",
       "4. **Rework Rate**:\n",
       "   - **Specific**: The percentage of declarations that require rework or corrections.\n",
       "   - **Measurable**: Number of reworked cases divided by the total number of cases.\n",
       "   - **Achievable**: Set a target based on historical performance and improvement initiatives.\n",
       "   - **Relevant**: High rework rates can indicate process inefficiencies and errors.\n",
       "   - **Time-bound**: Measured monthly or quarterly.\n",
       "\n",
       "5. **Customer Satisfaction**:\n",
       "   - **Specific**: The level of satisfaction of customers with the declaration process.\n",
       "   - **Measurable**: Survey scores or feedback ratings.\n",
       "   - **Achievable**: Set a target based on previous survey results.\n",
       "   - **Relevant**: Directly impacts the reputation and success of the organization.\n",
       "   - **Time-bound**: Measured semi-annually or annually.\n",
       "\n",
       "Next, let's validate these KPIs with available data to ensure that they are properly defined and measurable. We'll start by loading the event logs and examining their structure to determine how we can measure these KPIs. \n",
       "\n",
       "Let's execute the initial data loading and summary extraction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c14c8c6b2f34a248c1d466e4b16b0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0175edd37fed4af8aaebc273ecd16795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6abce48dfc44bba5023e3ac4b0a8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178ba0d109b544a286a654794c026a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The summaries of both the Domestic and International event logs indicate that they contain the following attributes:\n",
       "- `concept:name`: The name of the event.\n",
       "- `org:resource`: The resource (person or system) involved in the event.\n",
       "- `id`: The unique identifier for each event.\n",
       "- `time:timestamp`: The timestamp of the event.\n",
       "- `org:role`: The role associated with the resource.\n",
       "\n",
       "Given this structure, we can measure the KPIs as follows:\n",
       "\n",
       "1. **Cycle Time**:\n",
       "   - **Measurable**: Calculate the difference between the timestamps of the first and last events for each case (declaration).\n",
       "\n",
       "2. **Conformance Rate**:\n",
       "   - **Measurable**: Use process mining techniques (e.g., conformance checking) to compare the actual event log to a reference model.\n",
       "\n",
       "3. **Throughput Rate**:\n",
       "   - **Measurable**: Count the number of declarations processed within a specific time period.\n",
       "\n",
       "4. **Rework Rate**:\n",
       "   - **Measurable**: Identify events that indicate rework (e.g., repeated tasks) and calculate the proportion of cases that include such events.\n",
       "\n",
       "5. **Customer Satisfaction**:\n",
       "   - **Measurable**: This KPI may require additional data (e.g., survey results) that are not present in the event logs.\n",
       "\n",
       "Next, we will implement the calculations for these KPIs based on the available data and validate their SMART criteria. Letâ€™s start with the Cycle Time KPI. We'll calculate the average cycle time for both Domestic and International declarations.\n",
       "\n",
       "Let's proceed with the calculation for the Cycle Time KPI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It looks like there was an error because the `get_case_duration_avg` attribute does not exist in the `pm4py.statistics.traces.generic.log.case_statistics` module. \n",
       "\n",
       "We can calculate the cycle time differently using the timestamps in the event logs. Specifically, we can calculate the duration from the start to the end of each case. Let's use the first and last events of each case to compute these durations.\n",
       "\n",
       "Let's proceed with calculating the average cycle time using the correct approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It seems there's an issue with the module import. Let's try a different approach using available functions for calculating case durations directly from the log.\n",
       "\n",
       "We'll calculate the start and end times for each case and then determine the duration. Let's proceed with this approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are the calculated average cycle times:\n",
       "\n",
       "- **Domestic Declarations**: Approximately 276.61 hours\n",
       "- **International Declarations**: Approximately 2074.92 hours\n",
       "\n",
       "These values indicate the average time taken to complete a declaration from start to finish.\n",
       "\n",
       "Next steps:\n",
       "1. **Conformance Rate**:\n",
       "   - We'll use process mining techniques to compare the actual event log to a reference model.\n",
       "2. **Throughput Rate**:\n",
       "   - We'll count the number of declarations processed within specific time periods.\n",
       "3. **Rework Rate**:\n",
       "   - We'll identify and calculate the proportion of cases that include rework events.\n",
       "\n",
       "Would you like to proceed with calculating the Conformance Rate next, or focus on one of the other KPIs?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you think of useful KPIs for the processes?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream_events(inputs, config, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_chat_model_end\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1247\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly versions \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m of the schema is currently supported.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1244\u001b[0m     )\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclosing(event_stream):\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_stream:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/tracers/event_stream.py:778\u001b[0m, in \u001b[0;36m_astream_events_implementation_v1\u001b[0;34m(runnable, input, config, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, runnable\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[1;32m    776\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     runnable,\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    781\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    782\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    783\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    784\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    786\u001b[0m ):\n\u001b[1;32m    787\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:670\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    672\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:624\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    621\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    622\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    625\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1264\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1268\u001b[0m     )\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(\n\u001b[1;32m   1272\u001b[0m     read_channels(loop\u001b[38;5;241m.\u001b[39mchannels, output_keys)\n\u001b[1;32m   1273\u001b[0m )\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "config = {\"recursion_limit\": 10}\n",
    "inputs = {\"input\": \"Can you think of useful KPIs for the processes?\"}\n",
    "\n",
    "async for event in app.astream_events(inputs, config, version=\"v1\"):\n",
    "    if event[\"event\"] == \"on_chat_model_end\":\n",
    "        if event[\"data\"][\"output\"][\"generations\"][0][0][\"message\"].content:\n",
    "            display(Markdown(event[\"data\"][\"output\"][\"generations\"][0][0][\"message\"].content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-ha-process-mining-kRqu1UEl-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
