{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State graph agent for process mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den jüngsten Fortschritten der Künstlichen Intelligenz (KI) hat sich die Integration von großen Sprachmodellen (Large Language Models, LLMs) mit vordefinierten Workflows und Zustandsdiagrammen als leistungsstarkes Paradigma zur Automatisierung komplexer Aufgaben herausgestellt (vgl. Wang et al. [(2023)](https://arxiv.org/abs/2305.03722)). Dieses Notebook demonstriert einen innovativen Ansatz, bei dem ein LLM-Agent, ausgestattet mit einer Python-REPL, eigenständig Aufgaben löst, indem er schrittweise durch einen definierten Prozessablauf argumentiert. Die Implementierung basiert auf den Prinzipien des „Plan-and-Solve“- (vgl. LangGraph [(2024)](https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/2)) und „ReAct“-Prompting (vgl. Yao et al. [(2023)](https://arxiv.org/abs/2210.03629)), die es dem Modell ermöglichen, Aufgaben in handhabbare Schritte zu unterteilen und diese effektiv auszuführen.\n",
    "\n",
    "## Methodik\n",
    "\n",
    "Der Ansatz nutzt eine Kombination aus dem logischen Denken und Handeln innerhalb des LLMs, wodurch es ihm ermöglicht wird, durch ein Zustandsdiagramm zu navigieren, das die möglichen Übergänge und Ergebnisse der jeweiligen Aufgabe definiert. Durch die Integration einer strukturierten Anleitung in Form eines Flussdiagramms oder Zustandsgraphen generiert das LLM nicht nur Lösungen, sondern auch Erklärungen für seine Vorgehensweise, was die Nachvollziehbarkeit und Robustheit der Ergebnisse erhöht. Zusätzlich wird durch die Aufteilung komplexer Fragestellungen die Korrektheit verbessert und Haluzinationen minimiert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/img/plan-and-execute.png\" width=\"750\">](https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/img/plan-and-execute.png)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referenzen:**<br><br>\n",
    "1. Wang, L., Xu, W., Lan, Y., Hu, Z., Lan, Y., Lee, R. K.-W., & Lim, E.-P. (2023). <br>\n",
    "   &nbsp;&nbsp;&nbsp; Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. *arXiv preprint arXiv:2305.03722*.<br>\n",
    "   &nbsp;&nbsp;&nbsp; Link: https://arxiv.org/abs/2305.03722<br>\n",
    "2. LangGraph-Dokumentation.<br>\n",
    "   &nbsp;&nbsp;&nbsp; Plan-and-Execute. *LangGraph: A framework for stateful, multi-actor applications with LLMs*.<br>\n",
    "   &nbsp;&nbsp;&nbsp; Link: https://langchain-ai.github.io/langgraph/tutorials/plan-and-execute/plan-and-execute/<br>\n",
    "3. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023).<br>\n",
    "   &nbsp;&nbsp;&nbsp; ReAct: Synergizing Reasoning and Acting in Language Models. *arXiv preprint arXiv:2210.03629*.<br>\n",
    "   &nbsp;&nbsp;&nbsp; Link: https://arxiv.org/abs/2210.03629<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellwahl: GPT-4o\n",
    "\n",
    "In diesem Notebook wird GPT-4o verwendet, da es sich in den neuesten Benchmarks als eines der leistungsfähigsten Modelle erwiesen hat. Die Wahl dieses Modells gewährleistet eine hohe Genauigkeit und Effizienz bei der Bearbeitung der Aufgaben. Laut den aktuellen Ergebnissen der *Chatbot Arena*, einer offenen Plattform zur Bewertung von LLMs basierend auf menschlichen Präferenzen, zeigt GPT-4 herausragende Leistungen in Bezug auf Genauigkeit, Verständnis und Problemlösungsfähigkeiten.\n",
    "\n",
    "Das Modell wird in allen Schritten dieses Notebooks konsistent eingesetzt, kann aber nach belieben geändert werden. Eine günstigere Alternative stellt GPT-4o-mini dar.\n",
    "\n",
    "**Referenz:**<br><br>\n",
    "1. Chiang, W.-L., Zheng, L., Sheng, Y., Angelopoulos, A. N., Li, T., Li, D., Zhang, H., Zhu, B., Jordan, M., Gonzalez, J. E., & Stoica, I. (2024).<br>\n",
    "   &nbsp;&nbsp;&nbsp; Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference. *arXiv preprint arXiv:2403.04132*.<br>\n",
    "   &nbsp;&nbsp;&nbsp; Link: https://arxiv.org/abs/2403.04132<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-radius: 15px;\"> <b>Hinweis:</b> Das ausführen des folgenden Codes erfordert eine Datei <i>.env</i> im Root das Projektes mit der Variable `OPENAI_API_KEY`. </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das verwendete Modell kann hier angepasst werden\n",
    "MODEL_NAME = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Laden des OPENAI_API_KEY von der .env Datei\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einsatz von Tools\n",
    "\n",
    "Tools sind spezialisierte Werkzeuge, die einem Large Language Model (LLM) zusätzliche Fähigkeiten verleihen. Sie ermöglichen es dem Modell, über das reine Textverständnis hinaus zu agieren und spezifische Aufgaben wie das Ausführen von Code oder das Analysieren von Daten durchzuführen. Das Konzept der Tool-Nutzung durch LLMs wurde erstmals im Rahmen des *Toolformer*-Ansatzes eingeführt, wie im Paper \"Toolformer: Language Models Can Teach Themselves to Use Tools\" beschrieben (vgl. Schick et al. [(2023)](https://arxiv.org/abs/2302.04761)). Dieses Paper zeigt, wie LLMs ihre Funktionalität durch den Einsatz externer Werkzeuge erheblich erweitern können.\n",
    "\n",
    "In diesem Notebook steht dem GPT-4o Modell das `PythonREPLTool` zur Verfügung. Dieses Tool erlaubt es dem Modell, Python-Code direkt auszuführen und so den Datensatz eigenständig zu analysieren. Die Integration des PythonREPLTools ist entscheidend, da viele Aufgaben, wie die Datenverarbeitung und -analyse, die direkte Ausführung von Python-Befehlen erfordern. Ohne dieses Tool könnte das Modell zwar theoretisch Lösungen vorschlagen, wäre jedoch nicht in der Lage, diese praktisch umzusetzen und zu verifizieren.\n",
    "\n",
    "Zusätzliche Tools könnten in Zukunft hinzugefügt werden, um die Fähigkeiten des Modells weiter zu erweitern.\n",
    "\n",
    "**Referenz:** <br><br>\n",
    "\n",
    "1. Schick, T., Dwivedi-Yu, J., Raileanu, R., et al. (2023).<br>\n",
    "   &nbsp;&nbsp;&nbsp; Toolformer: Language Models Can Teach Themselves to Use Tools. *arXiv preprint arXiv:2302.04761*.<br>\n",
    "   &nbsp;&nbsp;&nbsp; Link: https://arxiv.org/abs/2302.04761<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "# Potentiell könnten weitere Tools hinzugefügt werden\n",
    "# Aktuell wird nur das PythonREPLTool verwendet\n",
    "tools = [PythonREPLTool(verbose=True)] # verbose=True gibt die Ausgaben des Tools auf der Konsole aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant. You are executing a plan to answer a process mining task question.\n",
    "For this you have two dataset available that the python tool can load:\n",
    "- Data/DomesticDeclarations.xes\n",
    "- Data/InternationalDeclarations.xes\n",
    "You can get started with:\n",
    "\n",
    "```python\n",
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "\n",
    "# Load the event logs\n",
    "domestic_log = xes_importer.apply('Data/DomesticDeclarations.xes')\n",
    "international_log = xes_importer.apply('Data/InternationalDeclarations.xes')\n",
    "\n",
    "# Print the summary of the logs to understand the structure\n",
    "domestic_summary = pm4py.get_event_attributes(domestic_log)\n",
    "international_summary = pm4py.get_event_attributes(international_log)\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# Prompt Template vorbereiten\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(SYSTEM_PROMPT),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "prompt.pretty_print()\n",
    "\n",
    "# LLM initialisieren\n",
    "llm = ChatOpenAI(model=MODEL_NAME)\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Markdown, display\n",
    "# test_runnable = agent_executor\n",
    "# md_answer =test_runnable.invoke({\"messages\": [(\"user\", \"What attributes do the logs have?\")]})[\"messages\"][-1].content\n",
    "\n",
    "# display(Markdown(md_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, TypedDict\n",
    "\n",
    "# Der State des Agents wird in einem TypedDict definiert\n",
    "# Dort werden alle Informationen gespeichert, die der Agent benötigt, um den nächsten Schritt vorherzusagen\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow to solve the process mining task using python.\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Erstellen des planners, diese kann nur im 'Plan' Schema antworten\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the process mining task, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "The Executer Agent will have a PythonREPL tool to execute your plan and data will be available.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "planner = planner_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").with_structured_output(Plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
    ")\n",
    "\n",
    "# Der replanner kann nur im 'Act' Schema antworten\n",
    "# Er kann entweder eine Response oder einen Plan zurückgeben\n",
    "replanner = replanner_prompt | ChatOpenAI(\n",
    "    model=MODEL_NAME, temperature=0\n",
    ").with_structured_output(Act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"messages\": [(\"user\", task_formatted)]}\n",
    "    )\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    output = await replanner.ainvoke(state)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        return {\"plan\": output.action.steps}\n",
    "\n",
    "\n",
    "def should_end(state: PlanExecute) -> Literal[\"agent\", \"__end__\"]:\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"__end__\"\n",
    "    else:\n",
    "        return \"agent\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "# Planner Node\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "\n",
    "# Executer Node\n",
    "workflow.add_node(\"agent\", execute_step)\n",
    "\n",
    "# Replan Node\n",
    "workflow.add_node(\"replan\", replan_step)\n",
    "\n",
    "# Von Start gehen wir zuerst zum planner\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# Von planner, gehen wir zum agent\n",
    "workflow.add_edge(\"planner\", \"agent\")\n",
    "\n",
    "# Von agent, gehen wir zum replan\n",
    "workflow.add_edge(\"agent\", \"replan\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"replan\",\n",
    "    # Wenn der replaner eine Response zurückgibt, dann endet der Prozess\n",
    "    should_end,\n",
    ")\n",
    "\n",
    "# Das kompilieren des Workflows \n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"border-radius: 15px;\"> <b>Warnung:</b> Die Verwendung größerer Modelle wie GPT-4 kann bis zu 1€ pro Anruf verursachen. Über das <i>recursion_limit</i> können die maximalen Kosten eingeschränkt werden.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keno/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To define the key objectives of the process being analyzed, we need to understand the context and purpose of the processes captured in the event logs. Let's start by examining the summaries of the DomesticDeclarations.xes and InternationalDeclarations.xes logs to get insights into the activities, cases, and event attributes. This will help us understand the processes better and define their key objectives.\n",
       "\n",
       "I'll proceed to load the logs and print their summaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b585e52a90fa4ce6add812ec0ed5b38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c179aaecf2b44468897d09d020ab8c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e58bd5f00cd4a78b7a0b82fd7bb174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54903563c0fe40938268a2ec1fa462b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mcontent='' name='Python_REPL' tool_call_id='call_ZdZu0YP5nCvSeVzJMqTwFqPb'\u001b[0m['concept:name', 'org:resource', 'id', 'time:timestamp', 'org:role']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The summaries of the logs indicate that both event logs contain the following attributes:\n",
       "\n",
       "- `concept:name`: The name of the event (activity).\n",
       "- `org:resource`: The resource (person or system) involved in the event.\n",
       "- `id`: The unique identifier for each event.\n",
       "- `time:timestamp`: The timestamp when the event occurred.\n",
       "- `org:role`: The role of the resource involved.\n",
       "\n",
       "Based on these attributes, we can infer that the processes involve various activities performed by different resources at specific times, with each event having a unique identifier and associated role.\n",
       "\n",
       "### Key Objectives\n",
       "To define the key objectives of the processes being analyzed, we can consider the following:\n",
       "\n",
       "1. **Efficiency**: Ensure that the process is completed in a timely manner with minimal delays.\n",
       "2. **Effectiveness**: Ensure that the process achieves its intended outcomes and goals.\n",
       "3. **Compliance**: Ensure that the process adheres to relevant regulations, standards, and policies.\n",
       "4. **Resource Utilization**: Optimize the allocation and utilization of resources (both human and system) involved in the process.\n",
       "5. **Quality**: Ensure that the process outputs meet the required quality standards and customer expectations.\n",
       "6. **Transparency**: Provide visibility into the process for stakeholders to monitor and understand the progress and performance.\n",
       "\n",
       "These objectives can guide the analysis and improvement of the processes captured in the Domestic and International Declarations event logs. \n",
       "\n",
       "Would you like to proceed to the next step, or focus on any specific objective in more detail?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4940e992b9a4052b70cb1d9af04c732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa76976dda04fc8b08176476ca73292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11673c881d64881a566569b35b2bf7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6dfb2130e3b495b8da72247bbdbdcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Both the Domestic and International event logs have the following attributes:\n",
       "\n",
       "- `concept:name`: Name of the event or activity.\n",
       "- `org:resource`: The resource (e.g., person or system) performing the event.\n",
       "- `id`: Unique identifier for the event.\n",
       "- `time:timestamp`: Timestamp of when the event occurred.\n",
       "- `org:role`: The role of the resource performing the event.\n",
       "\n",
       "Next, we will identify the critical activities and milestones within these processes. This can be done by extracting the most frequent and significant activities from the logs. Let's proceed with analyzing the most frequent activities in both logs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It seems there was an error because the module `pm4py.statistics.traces.log` couldn't be found. The correct module to use for extracting the frequency of activities is `pm4py.statistics.end_activities.log` for end activities or `pm4py.statistics.start_activities.log` for start activities.\n",
       "\n",
       "Let's correct the approach and extract the most frequent activities from both logs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are the most frequent start and end activities for both the Domestic and International logs:\n",
       "\n",
       "### Domestic Log\n",
       "- **Top Start Activities:**\n",
       "  - `Declaration SUBMITTED by EMPLOYEE`: 10,365 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 135 occurrences\n",
       "\n",
       "- **Top End Activities:**\n",
       "  - `Payment Handled`: 10,043 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 134 occurrences\n",
       "  - `Declaration REJECTED by EMPLOYEE`: 284 occurrences\n",
       "  - `Declaration REJECTED by MISSING`: 30 occurrences\n",
       "  - `Declaration REJECTED by ADMINISTRATION`: 5 occurrences\n",
       "  - `Declaration REJECTED by SUPERVISOR`: 4 occurrences\n",
       "\n",
       "### International Log\n",
       "- **Top Start Activities:**\n",
       "  - `Start trip`: 740 occurrences\n",
       "  - `Declaration SUBMITTED by EMPLOYEE`: 407 occurrences\n",
       "  - `Permit SUBMITTED by EMPLOYEE`: 5,294 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 8 occurrences\n",
       "\n",
       "- **Top End Activities:**\n",
       "  - `Payment Handled`: 5,646 occurrences\n",
       "  - `End trip`: 593 occurrences\n",
       "  - `Declaration SAVED by EMPLOYEE`: 54 occurrences\n",
       "  - `Permit REJECTED by MISSING`: 8 occurrences\n",
       "  - `Declaration REJECTED by MISSING`: 11 occurrences\n",
       "  - `Declaration REJECTED by EMPLOYEE`: 130 occurrences\n",
       "  - `Declaration FINAL_APPROVED by SUPERVISOR`: 1 occurrence\n",
       "  - `Send Reminder`: 2 occurrences\n",
       "  - `Request Payment`: 3 occurrences\n",
       "  - `Declaration REJECTED by SUPERVISOR`: 1 occurrence\n",
       "\n",
       "These activities represent critical steps and milestones within the processes. The next steps would be to determine the desired outcomes and performance standards for each activity and select appropriate KPIs to measure their efficiency, effectiveness, and quality."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To determine the desired outcomes and performance standards for each activity in the event logs, we need to understand the structure of the logs and the typical activities that occur in each process. This information will help us define specific outcomes and standards for each activity.\n",
       "\n",
       "Let's start by loading the event logs and summarizing their structures to identify the activities and attributes present in each log. \n",
       "\n",
       "I'll execute the initial code to load the logs and print the summaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To select Key Performance Indicators (KPIs) that measure the efficiency, effectiveness, and quality of the process, we need to first understand the structure and the key attributes of the event logs available. This will help us identify the relevant data points that can be used to measure these aspects.\n",
       "\n",
       "Let's start by loading the event logs and printing the summary of the logs to understand their structure and attributes.\n",
       "\n",
       "I'll execute the following steps:\n",
       "1. Load the event logs for both `DomesticDeclarations` and `InternationalDeclarations`.\n",
       "2. Print the summary of the logs to identify key attributes.\n",
       "\n",
       "I will start by loading the event logs and printing their summaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcc43890f3e47efa6a202c3f7456971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e08152e7621404798afd67ccd16dd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The summary of the logs indicates the following key attributes are available for both domestic and international declarations:\n",
       "\n",
       "- `concept:name`: The name of the event.\n",
       "- `org:resource`: The resource (person or system) responsible for the event.\n",
       "- `id`: The unique identifier for the event.\n",
       "- `time:timestamp`: The timestamp of when the event occurred.\n",
       "- `org:role`: The role associated with the event.\n",
       "\n",
       "Based on these attributes, we can select KPIs that measure the efficiency, effectiveness, and quality of the process:\n",
       "\n",
       "### Efficiency KPIs:\n",
       "1. **Cycle Time**: The total time taken to complete a process from start to finish (`time:timestamp`).\n",
       "2. **Resource Utilization**: The workload distribution among different resources (`org:resource`).\n",
       "\n",
       "### Effectiveness KPIs:\n",
       "1. **Throughput**: The number of processes completed within a specific time frame (`id` and `time:timestamp`).\n",
       "2. **Process Compliance**: The adherence to predefined process steps (`concept:name`).\n",
       "\n",
       "### Quality KPIs:\n",
       "1. **Error Rate**: The number of deviations or exceptions from the standard process (`concept:name` indicating exceptions or reworks).\n",
       "2. **Satisfaction Rate**: Feedback from stakeholders (though not directly available in the logs, can be correlated with `org:role` and `concept:name`).\n",
       "\n",
       "These KPIs are specific to the available data attributes and can be measured, achieved, and are relevant to the process. They can also be time-bound by analyzing the `time:timestamp` attribute.\n",
       "\n",
       "Next, we can proceed to validate these KPIs with stakeholders to ensure they align with business goals and then move on to implement and collect data for analysis.\n",
       "\n",
       "Would you like to proceed with any additional analysis or validation steps for these KPIs?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To ensure that the KPIs for the process mining task are specific, measurable, achievable, relevant, and time-bound (SMART), we need to define the KPIs in the context of the available datasets. Here are some potential KPIs we could consider:\n",
       "\n",
       "1. **Cycle Time**:\n",
       "   - **Specific**: The total time taken to complete a declaration from start to finish.\n",
       "   - **Measurable**: Average cycle time in days/hours.\n",
       "   - **Achievable**: Based on historical data, set a target cycle time.\n",
       "   - **Relevant**: Directly impacts customer satisfaction and operational efficiency.\n",
       "   - **Time-bound**: Measured monthly or quarterly.\n",
       "\n",
       "2. **Conformance Rate**:\n",
       "   - **Specific**: The percentage of declarations that follow the standard process model.\n",
       "   - **Measurable**: Number of conformant cases divided by the total number of cases.\n",
       "   - **Achievable**: Set a target based on industry standards or historical data.\n",
       "   - **Relevant**: Ensures adherence to the defined process, reducing errors and exceptions.\n",
       "   - **Time-bound**: Measured monthly or quarterly.\n",
       "\n",
       "3. **Throughput Rate**:\n",
       "   - **Specific**: The number of declarations processed within a specific time period.\n",
       "   - **Measurable**: Number of declarations per week/month.\n",
       "   - **Achievable**: Based on resource capacity and historical data.\n",
       "   - **Relevant**: Indicates the efficiency of the process in handling workload.\n",
       "   - **Time-bound**: Measured weekly or monthly.\n",
       "\n",
       "4. **Rework Rate**:\n",
       "   - **Specific**: The percentage of declarations that require rework or corrections.\n",
       "   - **Measurable**: Number of reworked cases divided by the total number of cases.\n",
       "   - **Achievable**: Set a target based on historical performance and improvement initiatives.\n",
       "   - **Relevant**: High rework rates can indicate process inefficiencies and errors.\n",
       "   - **Time-bound**: Measured monthly or quarterly.\n",
       "\n",
       "5. **Customer Satisfaction**:\n",
       "   - **Specific**: The level of satisfaction of customers with the declaration process.\n",
       "   - **Measurable**: Survey scores or feedback ratings.\n",
       "   - **Achievable**: Set a target based on previous survey results.\n",
       "   - **Relevant**: Directly impacts the reputation and success of the organization.\n",
       "   - **Time-bound**: Measured semi-annually or annually.\n",
       "\n",
       "Next, let's validate these KPIs with available data to ensure that they are properly defined and measurable. We'll start by loading the event logs and examining their structure to determine how we can measure these KPIs. \n",
       "\n",
       "Let's execute the initial data loading and summary extraction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c14c8c6b2f34a248c1d466e4b16b0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0175edd37fed4af8aaebc273ecd16795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/10500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6abce48dfc44bba5023e3ac4b0a8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178ba0d109b544a286a654794c026a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/6449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The summaries of both the Domestic and International event logs indicate that they contain the following attributes:\n",
       "- `concept:name`: The name of the event.\n",
       "- `org:resource`: The resource (person or system) involved in the event.\n",
       "- `id`: The unique identifier for each event.\n",
       "- `time:timestamp`: The timestamp of the event.\n",
       "- `org:role`: The role associated with the resource.\n",
       "\n",
       "Given this structure, we can measure the KPIs as follows:\n",
       "\n",
       "1. **Cycle Time**:\n",
       "   - **Measurable**: Calculate the difference between the timestamps of the first and last events for each case (declaration).\n",
       "\n",
       "2. **Conformance Rate**:\n",
       "   - **Measurable**: Use process mining techniques (e.g., conformance checking) to compare the actual event log to a reference model.\n",
       "\n",
       "3. **Throughput Rate**:\n",
       "   - **Measurable**: Count the number of declarations processed within a specific time period.\n",
       "\n",
       "4. **Rework Rate**:\n",
       "   - **Measurable**: Identify events that indicate rework (e.g., repeated tasks) and calculate the proportion of cases that include such events.\n",
       "\n",
       "5. **Customer Satisfaction**:\n",
       "   - **Measurable**: This KPI may require additional data (e.g., survey results) that are not present in the event logs.\n",
       "\n",
       "Next, we will implement the calculations for these KPIs based on the available data and validate their SMART criteria. Let’s start with the Cycle Time KPI. We'll calculate the average cycle time for both Domestic and International declarations.\n",
       "\n",
       "Let's proceed with the calculation for the Cycle Time KPI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It looks like there was an error because the `get_case_duration_avg` attribute does not exist in the `pm4py.statistics.traces.generic.log.case_statistics` module. \n",
       "\n",
       "We can calculate the cycle time differently using the timestamps in the event logs. Specifically, we can calculate the duration from the start to the end of each case. Let's use the first and last events of each case to compute these durations.\n",
       "\n",
       "Let's proceed with calculating the average cycle time using the correct approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It seems there's an issue with the module import. Let's try a different approach using available functions for calculating case durations directly from the log.\n",
       "\n",
       "We'll calculate the start and end times for each case and then determine the duration. Let's proceed with this approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are the calculated average cycle times:\n",
       "\n",
       "- **Domestic Declarations**: Approximately 276.61 hours\n",
       "- **International Declarations**: Approximately 2074.92 hours\n",
       "\n",
       "These values indicate the average time taken to complete a declaration from start to finish.\n",
       "\n",
       "Next steps:\n",
       "1. **Conformance Rate**:\n",
       "   - We'll use process mining techniques to compare the actual event log to a reference model.\n",
       "2. **Throughput Rate**:\n",
       "   - We'll count the number of declarations processed within specific time periods.\n",
       "3. **Rework Rate**:\n",
       "   - We'll identify and calculate the proportion of cases that include rework events.\n",
       "\n",
       "Would you like to proceed with calculating the Conformance Rate next, or focus on one of the other KPIs?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you think of useful KPIs for the processes?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app\u001b[38;5;241m.\u001b[39mastream_events(inputs, config, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_chat_model_end\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:1247\u001b[0m, in \u001b[0;36mRunnable.astream_events\u001b[0;34m(self, input, config, version, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly versions \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m of the schema is currently supported.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1244\u001b[0m     )\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m aclosing(event_stream):\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m event_stream:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/tracers/event_stream.py:778\u001b[0m, in \u001b[0;36m_astream_events_implementation_v1\u001b[0;34m(runnable, input, config, include_names, include_types, include_tags, exclude_names, exclude_types, exclude_tags, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m root_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, runnable\u001b[38;5;241m.\u001b[39mget_name())\n\u001b[1;32m    776\u001b[0m \u001b[38;5;66;03m# Ignoring mypy complaint about too many different union combinations\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# This arises because many of the argument types are unions\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m _astream_log_implementation(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     runnable,\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    781\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    782\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    783\u001b[0m     diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    784\u001b[0m     with_streamed_output_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    786\u001b[0m ):\n\u001b[1;32m    787\u001b[0m     run_log \u001b[38;5;241m=\u001b[39m run_log \u001b[38;5;241m+\u001b[39m log\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m encountered_start_event:\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# Yield the start event for the root runnable.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:670\u001b[0m, in \u001b[0;36m_astream_log_implementation\u001b[0;34m(runnable, input, config, stream, diff, with_streamed_output_list, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;66;03m# Wait for the runnable to finish, if not cancelled (eg. by break)\u001b[39;00m\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    672\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langchain_core/tracers/log_stream.py:624\u001b[0m, in \u001b[0;36m_astream_log_implementation.<locals>.consume_astream\u001b[0;34m()\u001b[0m\n\u001b[1;32m    621\u001b[0m prev_final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    622\u001b[0m final_output: Optional[Output] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mastream(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    625\u001b[0m     prev_final_output \u001b[38;5;241m=\u001b[39m final_output\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/code-ha-process-mining-kRqu1UEl-py3.11/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1264\u001b[0m, in \u001b[0;36mPregel.astream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;66;03m# handle exit\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(\n\u001b[1;32m   1265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout hitting a stop condition. You can increase the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit by setting the `recursion_limit` config key.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1268\u001b[0m     )\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(\n\u001b[1;32m   1272\u001b[0m     read_channels(loop\u001b[38;5;241m.\u001b[39mchannels, output_keys)\n\u001b[1;32m   1273\u001b[0m )\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 10 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key."
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import json\n",
    "\n",
    "config = {\"recursion_limit\": 10}\n",
    "inputs = {\"input\": \"Can you think of useful KPIs for the processes?\"}\n",
    "\n",
    "async for event in app.astream_events(inputs, config, version=\"v1\"):\n",
    "    if event[\"event\"] == \"on_chat_model_end\":\n",
    "        if event[\"data\"][\"output\"][\"generations\"][0][0][\"message\"].content:\n",
    "            display(Markdown(event[\"data\"][\"output\"][\"generations\"][0][0][\"message\"].content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stärken und Schwächen des LLM-basierten Prototyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Output des Agenten zeigt die iterative Natur von Process Mining, bringt aber auch einige Schwächen zum Vorschein:\n",
    "\n",
    "1. **Iterative Versuche und Modulfehler**:\n",
    "   - Der Agent stieß mehrfach auf Probleme mit Modulimporten und falschen Funktionen, besonders bei der Berechnung von Kennzahlen wie der Durchlaufzeit. Dies liegt daran, dass sich das `pm4py`-Paket geändert hat und der Agent keinen Zugriff auf die aktuelle Dokumentation hat. Dadurch musste er mehrere Versuche unternehmen, um den richtigen Code auszuführen. Diese Versuche könnten reduziert werden, wenn der Agent entweder Zugriff auf die Dokumentation hätte oder eigenständig Websuchen durchführen könnte.\n",
    "\n",
    "2. **Daten-Neuladen**:\n",
    "   - Der Agent lädt die Event-Logs für jeden Schritt neu, was ineffizient ist. Dies passiert, weil ein separater Multiprocessing-Prozess verwendet wird, wodurch der Kontext verloren geht. Hier könnte eine Optimierung durch Zwischenspeicherung der Daten helfen.\n",
    "\n",
    "3. **Zusammenfassung und KPIs**:\n",
    "   - Der Agent hat die wichtigsten Attribute der Event-Logs korrekt identifiziert und sinnvolle KPIs wie Durchlaufzeit, Konformitätsrate und Nacharbeitsrate vorgeschlagen. Diese KPIs sind relevant und passen zu den verfügbaren Daten.\n",
    "\n",
    "4. **Proof of Concept**:\n",
    "   - Trotz der genannten Herausforderungen zeigt der Agent, dass LangGraph für iterative Aufgaben im Process Mining geeignet ist. Allerdings müssen die Effizienz und der Zugriff auf aktuelle Bibliotheken verbessert werden, um das volle Potenzial auszuschöpfen.\n",
    "\n",
    "Zusammengefasst zeigt der Prototyp das Potenzial von LangGraph, hebt aber gleichzeitig Optimierungsbedarf bei der Ausführung und Infrastruktur hervor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-ha-process-mining-kRqu1UEl-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
